{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vacuum1234/test/blob/main/TPU_experiment_copy_of_Aika_LSTM_music_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgprfYyB9wUT",
        "outputId": "b856ad18-838d-400b-bb21-bee3ad75ce35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/gdrive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/gdrive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "strategy = tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER))\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "\n",
        "tpu_model.summary()\n",
        "\n",
        "tpu_number = 8\n",
        "batch_size=128 * tpu_number\n",
        "\n",
        "history = tpu_model.fit(X_tr, Y_tr,\n",
        "                        epochs=100,\n",
        "                        batch_size=batch_size,\n",
        "                        validation_split=0.2)\n",
        "tpu_model.evaluate(X_val, Y_val, batch_size=batch_size)\n",
        "tpu_model.save_weights('./our_tpu_model.h5')"
      ],
      "metadata": {
        "id": "gsZkMb7Ud_H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network1(network_input, n_vocab): #original\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ],
      "metadata": {
        "id": "kOmz6Qv4d_Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6uxzHB8_wqc"
      },
      "source": [
        "Ref: \\\\\n",
        "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPU: https://matthewmcateer.me/blog/using-tpus-in-google-colab/"
      ],
      "metadata": {
        "id": "M9Qj5nyUeo-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_v39vBj-mIQ",
        "outputId": "e14814f8-fd09-4ec6-e8ae-9344d3185380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Classical-Piano-Composer'...\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Total 334 (delta 0), reused 0 (delta 0), pack-reused 334\u001b[K\n",
            "Receiving objects: 100% (334/334), 721.79 MiB | 32.21 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ],
      "source": [
        "#change to the desired destination directory\n",
        "#%cd /content/gdrive/MyDrive/Github-Clones/\n",
        "\n",
        "#clone the github, only need to do this once to create the subdirectory\n",
        "#!git clone https://github.com/Skuldur/Classical-Piano-Composer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trkBh5kY-myN",
        "outputId": "efeff2bd-597c-4946-c87c-4ef88fafd021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-czzQFau-m4o",
        "outputId": "2643b3f9-1876-4efe-caab-a3004579e6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv_e800T-LFF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import converter, instrument, note, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "#from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQf_lrPYqXqz"
      },
      "source": [
        "# Train the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jENVKJ_s-m_6"
      },
      "outputs": [],
      "source": [
        "#for original google acct\n",
        "def train_network(weights_path, network_choice):\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "    print('n_vocab =', n_vocab)\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    if network_choice == 1:\n",
        "      model = create_network1(network_input, n_vocab)\n",
        "    if network_choice == 2:\n",
        "      model = create_network2(network_input, n_vocab)\n",
        "    if network_choice == 3:\n",
        "      model = create_network3(network_input, n_vocab)\n",
        "    if network_choice == 4:\n",
        "      model = create_network4(network_input, n_vocab)\n",
        "    if network_choice == 5:\n",
        "      model = create_network5(network_input, n_vocab)\n",
        "    train(model, network_input, network_output, weights_path)\n",
        "\n",
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/*\"):\n",
        "\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse()\n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "    ndrops = 5\n",
        "    a1 = (sequence_length - ndrops)//2\n",
        "    a2 = a1 + 1\n",
        "    a3 = a1 + ndrops - 1\n",
        "    a4 = a3 + 1\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length - ndrops, 1):\n",
        "      sequence_in = notes[i:i + sequence_length]\n",
        "      sequence_out = notes[i + sequence_length]\n",
        " #       sequence_in = notes[i:i + (sequence_length-ndrops)/2]\n",
        " #       sequence_out = notes[i + sequence_length/2:i + sequence_length/2+ndrops]\n",
        "      network_input.append([note_to_int[char] for char in sequence_in])\n",
        "      network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "    # normalize the input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def create_network1(network_input, n_vocab): #original\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network2(network_input, n_vocab): #changed dropout to 0.1\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.1,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.1,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network3(network_input, n_vocab): #changed activation function to tanh\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network4(network_input, n_vocab): #changed lstm nodes to 256\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(256, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(256))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network5(network_input, n_vocab): #added another lstm layer\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def train(model, network_input, network_output, weights_path):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = weights_path + \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    #model.fit(network_input, network_output, epochs=2, batch_size=128, callbacks=callbacks_list)\n",
        "    model.fit(network_input, network_output, epochs=150, batch_size=128, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for test acct\n",
        "\n",
        "def train_network(weights_path, network_choice):\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "    print('n_vocab =', n_vocab)\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    if network_choice == 1:\n",
        "      model = create_network1(network_input, n_vocab)\n",
        "    if network_choice == 2:\n",
        "      model = create_network2(network_input, n_vocab)\n",
        "    if network_choice == 3:\n",
        "      model = create_network3(network_input, n_vocab)\n",
        "    if network_choice == 4:\n",
        "      model = create_network4(network_input, n_vocab)\n",
        "    if network_choice == 5:\n",
        "      model = create_network5(network_input, n_vocab)\n",
        "    train(model, network_input, network_output, weights_path)\n",
        "\n",
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"/content/gdrive/MyDrive/midi_songs/*\"):\n",
        "\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse()\n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/notes-2', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "    ndrops = 5\n",
        "    a1 = (sequence_length - ndrops)//2\n",
        "    a2 = a1 + 1\n",
        "    a3 = a1 + ndrops - 1\n",
        "    a4 = a3 + 1\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length - ndrops, 1):\n",
        "      sequence_in = notes[i:i + sequence_length]\n",
        "      sequence_out = notes[i + sequence_length]\n",
        " #       sequence_in = notes[i:i + (sequence_length-ndrops)/2]\n",
        " #       sequence_out = notes[i + sequence_length/2:i + sequence_length/2+ndrops]\n",
        "      network_input.append([note_to_int[char] for char in sequence_in])\n",
        "      network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "    # normalize the input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def create_network1(network_input, n_vocab): #original\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network2(network_input, n_vocab): #changed dropout to 0.1\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.1,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.1,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network3(network_input, n_vocab): #changed activation function to tanh\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network4(network_input, n_vocab): #changed lstm nodes to 256\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(256, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(256))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_network5(network_input, n_vocab): #added another lstm layer\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    return model\n",
        "\n",
        "def train(model, network_input, network_output, weights_path):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = weights_path + \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    #model.fit(network_input, network_output, epochs=2, batch_size=128, callbacks=callbacks_list)\n",
        "    model.fit(network_input, network_output, epochs=150, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "3X_l2NHsg6yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "eZdGR5cUr48R",
        "outputId": "8dac590e-d0f1-4cf1-c3fe-3700f486923a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/data/notes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0d7027738c06>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweights_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_choice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-006f55b633f4>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(weights_file, network_choice)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#with open('/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/data/notes', 'rb') as filepath:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#notes = pickle.load(filepath)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnotes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Get all pitch names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-d415b4f83ed6>\u001b[0m in \u001b[0;36mget_notes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mnotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalOrder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/data/notes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/data/notes'"
          ]
        }
      ],
      "source": [
        "#set weights path and filename\n",
        "network_choice=4\n",
        "weights_path = \"/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/weights/\" + str(network_choice) + \"/\"\n",
        "#weights_filename = \"weights-improvement-01-5.1848-bigger.hdf5\"\n",
        "#weights_filename = \"my_model_100_epoch.hdf5\"\n",
        "weights_filename = \"weights-improvement-01-5.2259-bigger.hdf5\"\n",
        "weights_file = weights_path + weights_filename\n",
        "\n",
        "generate(weights_file, network_choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V-X4R3Y-nEy",
        "outputId": "e10deb4d-74a7-4deb-c5b4-58c255e1ca6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/relmstheme-piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/rufus.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Eternal_Harvest.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FF4.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Ff7-Cinco.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/EyesOnMePiano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Life_Stream.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FF3_Battle_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/tpirtsd-piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/dayafter.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff4-fight1.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Kingdom_Hearts_Traverse_Town.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/In_Zanarkand.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/BlueStone_LastDungeon.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/sobf.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/thoughts.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/mining.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/redwings.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff7-mainmidi.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ultros.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/figaro.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Fierce_Battle_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff8-lfp.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/thenightmarebegins.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FFIX_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/z_aeristhemepiano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ultimafro.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Rachel_Piano_tempofix.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ahead_on_our_way_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Suteki_Da_Ne_(Piano_Version).mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff4pclov.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/pkelite4.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FFIXQuMarshP.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Oppressed.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/goldsaucer.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ViviinAlexandria.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff4_piano_collections-main_theme.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/gerudo.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff4-town.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FFIII_Edgar_And_Sabin_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff1battp.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/balamb.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/great_war.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FF6epitaph_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Ff7-Jenova_Absolute.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Rydia_pc.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Zelda_Overworld.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/caitsith.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/AT.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FFVII_BATTLE.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/0fithos.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/lurk_in_dark.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Ff4-BattleLust.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Kingdom_Hearts_Dearly_Beloved.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/DOS.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/OTD5YA.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Cids.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/waltz_de_choco.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Gold_Silver_Rival_Battle.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/fortresscondor.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff11_awakening_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/costadsol.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Still_Alive-1.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/decisive.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Finalfantasy6fanfarecomplete.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Fiend_Battle_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Fyw_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/8.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Finalfantasy5gilgameshp.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/HighwindTakestotheSkies.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/cosmo.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FF8_Shuffle_or_boogie_pc.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/bcm.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Ff7-One_Winged.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff4-airship.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/roseofmay-piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/FF3_Third_Phase_Final_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/sandy.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/VincentPiano.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/electric_de_chocobo.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff7themep.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/traitor.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/sera_.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/braska.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/path_of_repentance.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/JENOVA.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/dontbeafraid.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/ff6shap.mid\n",
            "Parsing /content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/midi_songs/tifap.mid\n",
            "n_vocab = 326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "316/359 [=========================>....] - ETA: 26s - loss: 4.9495"
          ]
        }
      ],
      "source": [
        "#set path to where weights will be stores\n",
        "network_choice = 5\n",
        "weights_path = \"/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/weights/\" + str(network_choice) + \"/\"\n",
        "train_network(weights_path, network_choice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I6LRAygryrn"
      },
      "source": [
        "# Generate Music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ28uFoeo0Ql"
      },
      "outputs": [],
      "source": [
        "\"\"\" This module generates notes for a midi file using the\n",
        "    trained neural network \"\"\"\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import instrument, note, stream, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import Activation\n",
        "\n",
        "def generate(weights_file, network_choice):\n",
        "    \"\"\" Generate a piano midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    #with open('/content/gdrive/MyDrive/Github-Clones/Classical-Piano-Composer/data/notes', 'rb') as filepath:\n",
        "        #notes = pickle.load(filepath)\n",
        "    notes=get_notes()\n",
        "    n_vocab=326\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences1(notes, pitchnames, n_vocab)\n",
        "\n",
        "    if network_choice==1:\n",
        "      model = create_network1(normalized_input, n_vocab)\n",
        "    if network_choice == 2:\n",
        "      model = create_network2(normalized_input, n_vocab)\n",
        "    if network_choice == 3:\n",
        "      model = create_network3(normalized_input, n_vocab)\n",
        "    if network_choice == 4:\n",
        "      model = create_network4(normalized_input, n_vocab)\n",
        "    if network_choice == 5:\n",
        "      model = create_network5(normalized_input, n_vocab)\n",
        "    model = load_weights(model, weights_file)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)\n",
        "\n",
        "def prepare_sequences1(notes, pitchnames, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    # map between notes and integers and back\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)\n",
        "\n",
        "def load_weights(model, weights_file):\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights(weights_file)\n",
        "    return model\n",
        "\n",
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "def create_midi(prediction_output):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='test_output'+str(network_choice)+\"-\"+weights_filename[20:23]+\".mid\")\n",
        "\n",
        "\n",
        "    #filename has network choice then epoch #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set weights path and filename\n",
        "network_choice=2\n",
        "weights_path = \"/content/gdrive/MyDrive/\"\n",
        "#weights_filename = \"weights-improvement-01-5.1848-bigger.hdf5\"\n",
        "#weights_filename = \"my_model_100_epoch.hdf5\"\n",
        "weights_filename = \"weights-improvement-139-0.1123-bigger.hdf5\"\n",
        "weights_file = weights_path + weights_filename\n",
        "\n",
        "\n",
        "\n",
        "generate(weights_file, network_choice)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gMXnTZOgEA1",
        "outputId": "3d9b747d-d057-47a9-f7d0-73bd7218c53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing /content/gdrive/MyDrive/midi_songs/cosmo.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Fiend_Battle_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/JENOVA.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/thenightmarebegins.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FF4.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff4-fight1.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Life_Stream.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/rufus.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Zelda_Overworld.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/figaro.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff8-lfp.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/BlueStone_LastDungeon.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/0fithos.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/dontbeafraid.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FFIX_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff4_piano_collections-main_theme.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/dayafter.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FFIII_Edgar_And_Sabin_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FF6epitaph_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ultros.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/roseofmay-piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/redwings.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/sobf.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/z_aeristhemepiano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/8.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/In_Zanarkand.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/waltz_de_choco.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/AT.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff4pclov.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Cids.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Finalfantasy5gilgameshp.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff7themep.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/electric_de_chocobo.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff4-airship.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FFVII_BATTLE.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Ff7-One_Winged.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/lurk_in_dark.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Oppressed.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/sera_.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/caitsith.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Suteki_Da_Ne_(Piano_Version).mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/DOS.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Ff7-Jenova_Absolute.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/balamb.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FF8_Shuffle_or_boogie_pc.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ahead_on_our_way_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FF3_Battle_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/bcm.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/traitor.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FFIXQuMarshP.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Finalfantasy6fanfarecomplete.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff1battp.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Eternal_Harvest.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/HighwindTakestotheSkies.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Fierce_Battle_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Gold_Silver_Rival_Battle.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/braska.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Rachel_Piano_tempofix.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/FF3_Third_Phase_Final_(Piano).mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Kingdom_Hearts_Traverse_Town.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/decisive.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/sandy.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/VincentPiano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/costadsol.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Ff7-Cinco.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/thoughts.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/path_of_repentance.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff4-town.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/mining.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Fyw_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Still_Alive-1.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/EyesOnMePiano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/fortresscondor.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/tpirtsd-piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/great_war.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Ff4-BattleLust.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ultimafro.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/goldsaucer.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ViviinAlexandria.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Rydia_pc.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/OTD5YA.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff7-mainmidi.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff6shap.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/relmstheme-piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/tifap.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/Kingdom_Hearts_Dearly_Beloved.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/pkelite4.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/ff11_awakening_piano.mid\n",
            "Parsing /content/gdrive/MyDrive/midi_songs/gerudo.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "8rfyOGV6AQZc",
        "outputId": "734db67b-5db7-4c45-8ee1-aaf143089294"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5f15418b3570>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "FJ9neE0vsYdg",
        "outputId": "2ebd3d52-0309-4377-f30a-61699381988e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.10.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.18.1 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Collecting chromedriver-py\n",
            "  Downloading chromedriver_py-121.0.6167.85-py3-none-any.whl (40.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chromedriver-py\n",
            "Successfully installed chromedriver-py-121.0.6167.85\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c5843180d675>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_experimental_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"excludeSwitches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"enable-automation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_experimental_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'useAutomationExtension'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'C:\\WebDrivers\\chromedriver.exe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.inipec.gov.it/cerca-pec/-/pecs/companies\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_to_be_available_and_switch_to_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"iframe[name^='a-'][src^='https://www.google.com/recaptcha/api2/anchor?']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!pip install chromedriver-py\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"start-maximized\")\n",
        "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "options.add_experimental_option('useAutomationExtension', False)\n",
        "driver = webdriver.Chrome(options=options, executable_path=r'C:\\WebDrivers\\chromedriver.exe')\n",
        "driver.get(\"https://www.inipec.gov.it/cerca-pec/-/pecs/companies\")\n",
        "WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR,\"iframe[name^='a-'][src^='https://www.google.com/recaptcha/api2/anchor?']\")))\n",
        "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//span[@id='recaptcha-anchor']\"))).click()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
